{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9f6be7",
   "metadata": {},
   "source": [
    "# CSME2 Bonus Point Assignment II Part 3\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 2.1.0, released 2022-02-09</div>\n",
    "For task instructions, refer to the assignment PDF.\n",
    "\n",
    "* The parts of the code you are to implement are indicated via `# FILL HERE` comments.\n",
    "* Some cells create export file in the `output/` folder. _Include whole `output/` folder in your submission_.\n",
    "* Make sure you restart the notebook's kernel and run everything in one go before submission\n",
    "* DO NOT CLEAR THE OUTPUT of the notebook you are submitting.\n",
    "\n",
    "_v2.1.0 Fix imports and set default dtype to float_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c15c1814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path('.')\n",
    "DATA = ROOT / 'data'\n",
    "EXAMPLE_IMAGE = DATA / 'example_image.png'\n",
    "OUTPUT = ROOT / 'output'\n",
    "\n",
    "OUTPUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Enable reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.set_deterministic(True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8edc226c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-896a3519b2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     ):\n\u001b[0;32m--> 226\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    227\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    106\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    107\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
     ]
    }
   ],
   "source": [
    "##### FILL HERE #####\n",
    "#### Question 3.2 ###\n",
    "\n",
    "#Import the training and test data as two torch.utils.data.Dataset objects \n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = ImageFolder(DATA / 'train', transform=tfm)\n",
    "val_ds = ImageFolder(DATA / 'test', transform=tfm)\n",
    "\n",
    "train_ok_idx=5000\n",
    "\n",
    "#Plot 5 figures of each class of training dataset\n",
    "plt.figure(figsize=(12,12))\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(5,2,2*i+1)\n",
    "    plt.imshow(transform(train_ds[i][0]))\n",
    "    plt.title(f'Defect_{i+1}')\n",
    "    plt.subplot(5,2,2*i+2)\n",
    "    plt.imshow(transform(train_ds[train_ok_idx+i][0]))\n",
    "    plt.title(f'OK_{i+1}')\n",
    "    \n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10265d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpLeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.3 ###\n",
    "        \n",
    "        # The arguments for commonly used modules:\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        \n",
    "        #input size: [3, 128, 128]\n",
    "        self.cnn_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, 3, 1, 1),  #F_in: 3, F_out: 16, K=3, S=1, P=1\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2, 0)       #K=2, S=2\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * 64 * 64, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        #####################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.3 ###\n",
    "        \n",
    "        x = self.cnn_layers(x)\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "        #####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbe93a",
   "metadata": {},
   "source": [
    "_v2.1.0: fix typos, cast tensors to float and reshape outputs to labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, batch_size, epochs, learning_rate, qname):\n",
    "    n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print(f'Number of trainable parameters: {n_params}')\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    \n",
    "    ##### FILL HERE #####\n",
    "    #### Question 3.4 ###\n",
    "    # Create dataloader from train_ds\n",
    "    \n",
    "    dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #####################\n",
    "    \n",
    "    with tqdm(range(epochs)) as pbar:\n",
    "        for epoch in pbar:  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(dataloader):\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs.to(torch.float32))\n",
    "                outputs = outputs.reshape(labels.shape)\n",
    "                loss = criterion(outputs, labels.to(torch.float32))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # training curve\n",
    "                running_loss += loss.item() * inputs.shape[0]\n",
    "            \n",
    "            print(f'train_loss= {running_loss:.5f}')\n",
    "            \n",
    "            ##### FILL HERE #####\n",
    "            #### Question 3.4 ###\n",
    "            # Compute Validation loss\n",
    "\n",
    "            net.eval()                              # set model to evalutation mode\n",
    "            val_loss = 0.0\n",
    "              \n",
    "            with torch.no_grad():                   # disable gradient calculation\n",
    "                for data in valid_dataloader:\n",
    "                    inputs, labels = data\n",
    "                    outputs = net(inputs.to(torch.float32))   \n",
    "                    outputs = outputs.reshape(labels.shape)\n",
    "                    val_loss += criterion(outputs, labels.to(torch.float32)).item() * inputs.shape[0] \n",
    "                    \n",
    "                print(f'valid loss= {val_loss:.5f}')\n",
    "        \n",
    "            #####################\n",
    "            \n",
    "            losses.append([running_loss, val_loss])\n",
    "            pbar.set_description(f\"Loss {losses[-1][0]:.02f}/{losses[-1][1]:.02f}\")\n",
    "    \n",
    "    # Save outputs\n",
    "    with open(str(OUTPUT / f'{qname}.pt'), \"wb\") as f:\n",
    "        torch.save(net, f)\n",
    "    losses = np.array(losses)\n",
    "    plt.plot(np.arange(len(losses)), losses[:, 0], label=\"train\")\n",
    "    plt.plot(np.arange(len(losses)), losses[:, 1], label=\"validation\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(OUTPUT / f'{qname}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN HERE #####\n",
    "#### Question 3.4 ###\n",
    "net = SimpLeNet()\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "learning_rate = 0.0001  #The training does not go well, mainly due to the large learning rate\n",
    "qname = 'question_3-4'\n",
    "print(net)\n",
    "train(net, batch_size, epochs, learning_rate, qname)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2fd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out validation result\n",
    "valid_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "total_acc = 0\n",
    "with torch.no_grad():                   # disable gradient calculation\n",
    "    for data in valid_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        outputs = net(inputs.to(torch.float32))                           \n",
    "        acc = (torch.round(outputs[:,0])== labels.to(torch.float32)).float()\n",
    "        print(f\"batch acc: {acc.mean().item():.5f}\")\n",
    "        \n",
    "        total_acc += acc.sum().item()\n",
    "        \n",
    "print(f\"\\nOverall acc: {total_acc/len(val_ds):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.5 ###\n",
    "        \n",
    "        # 1. Add one more convolutional layer\n",
    "        # 2. Add batch normalization\n",
    "        self.cnn_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, 3, 1, 1),  # input size: [3, 128, 128]\n",
    "            torch.nn.BatchNorm2d(16), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2, 0),\n",
    "            \n",
    "            torch.nn.Conv2d(16, 32, 3, 1, 1), \n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(4, 4, 0)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32*16*16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        #####################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### FILL HERE #####\n",
    "        #### Question 3.5 ###\n",
    "        \n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "        #####################\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN HERE #####\n",
    "#### Question 3.5 ###\n",
    "convnet = ConvNet()\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "learning_rate = 0.0002\n",
    "qname = 'question_3-5'\n",
    "print(convnet)\n",
    "train(convnet, batch_size, epochs, learning_rate, qname)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb3235a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f2ff6a2900da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Print out validation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalid_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                   \u001b[0;31m# disable gradient calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_ds' is not defined"
     ]
    }
   ],
   "source": [
    "#Print out validation result\n",
    "valid_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "total_acc = 0\n",
    "with torch.no_grad():                   # disable gradient calculation\n",
    "    for data in valid_dataloader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        outputs = convnet(inputs.to(torch.float32))                           \n",
    "        acc = (torch.round(outputs[:,0])== labels.to(torch.float32)).float()\n",
    "        print(f\"batch acc: {acc.mean().item():.5f}\")\n",
    "        \n",
    "        total_acc += acc.sum().item()\n",
    "        \n",
    "print(f\"\\nOverall acc: {total_acc/len(val_ds):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fb5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
